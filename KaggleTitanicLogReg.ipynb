{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c51fe6",
   "metadata": {},
   "source": [
    "# Libraries and data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2dee7",
   "metadata": {},
   "source": [
    "We will first load all the necessary libraries and the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77bb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84bf071",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We now load the data\n",
    "traindf = pd.read_csv('train.csv')  # load the training data\n",
    "testdf = pd.read_csv('test.csv')  # load the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4778ec",
   "metadata": {},
   "source": [
    "# Imputation of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de885720",
   "metadata": {},
   "source": [
    "Let's check what is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2de071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f94a1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c32439",
   "metadata": {},
   "source": [
    "First we will impute the Age column with mean values. If we don't round the numbers to one decimal point there are too many decimal points which add no new knowledge to the age yet if we are working with very large data frames might pose an problem for speed. Ask Danny if this is true.\n",
    "\n",
    "Next, let's explore the Cabin column. This is not a numeric value so using mean or median as an imputation value is meaningless. We can try a random sample from the existing cabin value or something else. \n",
    "One option is to use the most common cabin designation. Considering there are many types it might be appropriate to use Unknown. This way we are not forcing anything on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ba1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['Age'] = traindf['Age'].fillna(traindf['Age'].mean())\n",
    "traindf['Cabin'] = traindf['Cabin'].fillna('Unknown')\n",
    "traindf['Embarked'] = traindf['Embarked'].fillna('Unknown')\n",
    "############################################################\n",
    "testdf['Fare'] = testdf['Fare'].fillna(testdf['Fare'].mean())\n",
    "testdf['Age'] = testdf['Age'].fillna(testdf['Age'].mean())\n",
    "testdf['Cabin'] = testdf['Cabin'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57348e31",
   "metadata": {},
   "source": [
    "# Data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7ff36",
   "metadata": {},
   "source": [
    "We will now bunch the age variable into children, age 0-10, young adults (11-30), adults(31-50) and seniors 50+.\n",
    "We will also bunch the cabin numbers into just the letter in front (ex cabin C85 becomes C, cabin B42 becomes B, etc).\n",
    "Sex will be transformed to male=0, female=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e95e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataEngineering(dfName):\n",
    "    df = dfName.copy()\n",
    "    bins = pd.IntervalIndex.from_breaks([0, 10, 31, 51, np.inf], closed='left')\n",
    "    df[\"AgeBin\"] = pd.cut(df.Age.values, bins).codes\n",
    "\n",
    "    # Transforming the cabin code to only show the letter of it (the first character in the string)\n",
    "    df['CabinLetter'] = df['Cabin'].astype(str).str[0]\n",
    "\n",
    "    # Sex, Cabin, Embarked to integer\n",
    "    df.replace({'Sex': {'female': 0, 'male': 1}}, inplace=True)\n",
    "    df.replace({'Embarked': {'S': 0, 'C': 1, 'Q' : 2, 'Unknown':3}}, inplace=True)\n",
    "    df.replace({'CabinLetter': {'U':0, 'C':1, 'B':2, 'D':3, 'G':4, 'F':5, 'E':6, 'T':7, 'A':8}}, inplace=True)\n",
    "    \n",
    "    # We remove all the variables that cannot have any effect like Name and Ticket. We replace Cabin with CabinLetter\n",
    "    df.drop(columns = ['Name', 'Ticket','Cabin'], axis=1, inplace=True)\n",
    "    \n",
    "    # We change PassengerID to be the index of the dataframe\n",
    "    df.set_index(\"PassengerId\", inplace=True) \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8efb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = dataEngineering(traindf)\n",
    "testdf = dataEngineering(testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fac54",
   "metadata": {},
   "source": [
    "# Data normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fa208",
   "metadata": {},
   "source": [
    "Let's look at the unique values in each column to see which can be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653cb75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass [3 2 1]\n",
      "Sex [1 0]\n",
      "Age [34.5        47.         62.         27.         22.         14.\n",
      " 30.         26.         18.         21.         30.27259036 46.\n",
      " 23.         63.         24.         35.         45.         55.\n",
      "  9.         48.         50.         22.5        41.         33.\n",
      " 18.5        25.         39.         60.         36.         20.\n",
      " 28.         10.         17.         32.         13.         31.\n",
      " 29.         28.5        32.5         6.         67.         49.\n",
      "  2.         76.         43.         16.          1.         12.\n",
      " 42.         53.         26.5        40.         61.         60.5\n",
      "  7.         15.         54.         64.         37.         34.\n",
      " 11.5         8.          0.33       38.         57.         40.5\n",
      "  0.92       19.         36.5         0.75        0.83       58.\n",
      "  0.17       59.         14.5        44.          5.         51.\n",
      "  3.         38.5       ]\n",
      "SibSp [0 1 2 3 4 5 8]\n",
      "Parch [0 1 3 2 4 6 5 9]\n",
      "Fare [  7.8292       7.           9.6875       8.6625      12.2875\n",
      "   9.225        7.6292      29.           7.2292      24.15\n",
      "   7.8958      26.          82.2667      61.175       27.7208\n",
      "  12.35         7.225        7.925       59.4          3.1708\n",
      "  31.6833      61.3792     262.375       14.5         61.9792\n",
      "  30.5         21.6792      31.5         20.575       23.45\n",
      "  57.75         8.05         9.5         56.4958      13.4167\n",
      "  26.55         7.85        13.          52.5542      29.7\n",
      "   7.75        76.2917      15.9         60.          15.0333\n",
      "  23.         263.          15.5792      29.125        7.65\n",
      "  16.1         13.5          7.725       21.           7.8792\n",
      "  42.4         28.5375     211.5         25.7         15.2458\n",
      " 221.7792      10.7083      14.4542      13.9          7.775\n",
      "  52.           7.7958      78.85         7.8542      55.4417\n",
      "   8.5167      22.525        7.8208       8.7125      15.0458\n",
      "   7.7792      31.6792       7.2833       6.4375      16.7\n",
      "  75.2417      15.75         7.25        23.25        28.5\n",
      "  25.4667      46.9        151.55        18.          51.8625\n",
      "  83.1583      35.62718849  12.1833      31.3875       7.55\n",
      "  13.775        7.7333      22.025       50.4958      34.375\n",
      "   8.9625      39.          36.75        53.1        247.5208\n",
      "  16.          69.55        32.5        134.5         10.5\n",
      "   8.1125      15.5         14.4        227.525       25.7417\n",
      "   7.05        73.5         42.5        164.8667      13.8583\n",
      "  27.4458      15.1         65.           6.4958      71.2833\n",
      "  75.25       106.425       30.           7.8875      27.75\n",
      " 136.7792       9.325       17.4         12.7375       0.\n",
      "  20.2125      39.6          6.95        81.8583      41.5792\n",
      "  45.5          9.35        93.5         14.1083       7.575\n",
      " 135.6333     146.5208     211.3375      79.2         15.7417\n",
      "   7.5792     512.3292      63.3583      51.4792      15.55\n",
      "  37.0042      14.4583      39.6875      11.5         50.\n",
      "  12.875       21.075       39.4         20.25        47.1\n",
      "  13.8625       7.7208      90.         108.9         22.3583    ]\n",
      "Embarked [2 0 1]\n",
      "AgeBin [2 3 1 0]\n",
      "CabinLetter [0 2 6 8 1 3 5 4]\n"
     ]
    }
   ],
   "source": [
    "for col in testdf:\n",
    "    print(col, testdf[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56e774",
   "metadata": {},
   "source": [
    "We see that Fare and Age are the only ones that should be normalized. The rest have only few unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b977ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(df): # A function to normalize only select columns ina  dataframe\n",
    "    col_names = ['Age', 'Fare']\n",
    "    features = df[col_names]\n",
    "    scaler = preprocessing.StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    "    df[col_names] = features\n",
    "# Ask Danny how to manke a function that has variable input. *args **kwargs What is that?\n",
    "# Now are age and fare to be scaled but what if we need to omit fare or maybe add two more columns to be scaled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "901909ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleData(traindf)\n",
    "scaleData(testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c31afe",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81295ea",
   "metadata": {},
   "source": [
    "We will split the data in X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d975033",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.447155\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.329</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>Survived</td>           <td>AIC:</td>         <td>814.8306</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-10-18 14:46</td>       <td>BIC:</td>         <td>857.9617</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>891</td>        <td>Log-Likelihood:</td>    <td>-398.42</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>8</td>            <td>LL-Null:</td>        <td>-593.33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>882</td>         <td>LLR p-value:</td>    <td>2.8102e-79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>        <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass</th>      <td>-0.4821</td>  <td>0.1235</td>   <td>-3.9021</td> <td>0.0001</td> <td>-0.7242</td> <td>-0.2399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex</th>         <td>-2.5311</td>  <td>0.1925</td>  <td>-13.1473</td> <td>0.0000</td> <td>-2.9084</td> <td>-2.1537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>         <td>-1.3767</td>  <td>0.1883</td>   <td>-7.3111</td> <td>0.0000</td> <td>-1.7458</td> <td>-1.0077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SibSp</th>       <td>-0.2866</td>  <td>0.1061</td>   <td>-2.7002</td> <td>0.0069</td> <td>-0.4946</td> <td>-0.0786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Parch</th>       <td>-0.1140</td>  <td>0.1168</td>   <td>-0.9759</td> <td>0.3291</td> <td>-0.3429</td> <td>0.1150</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fare</th>        <td>0.2844</td>   <td>0.1359</td>   <td>2.0936</td>  <td>0.0363</td> <td>0.0182</td>  <td>0.5507</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked</th>    <td>0.4178</td>   <td>0.1391</td>   <td>3.0034</td>  <td>0.0027</td> <td>0.1451</td>  <td>0.6904</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AgeBin</th>      <td>1.4405</td>   <td>0.2150</td>   <td>6.7014</td>  <td>0.0000</td> <td>1.0192</td>  <td>1.8618</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CabinLetter</th> <td>0.2355</td>   <td>0.0529</td>   <td>4.4476</td>  <td>0.0000</td> <td>0.1317</td>  <td>0.3392</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.329     \n",
       "Dependent Variable: Survived         AIC:              814.8306  \n",
       "Date:               2021-10-18 14:46 BIC:              857.9617  \n",
       "No. Observations:   891              Log-Likelihood:   -398.42   \n",
       "Df Model:           8                LL-Null:          -593.33   \n",
       "Df Residuals:       882              LLR p-value:      2.8102e-79\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     6.0000                                       \n",
       "------------------------------------------------------------------\n",
       "              Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "------------------------------------------------------------------\n",
       "Pclass       -0.4821    0.1235   -3.9021  0.0001  -0.7242  -0.2399\n",
       "Sex          -2.5311    0.1925  -13.1473  0.0000  -2.9084  -2.1537\n",
       "Age          -1.3767    0.1883   -7.3111  0.0000  -1.7458  -1.0077\n",
       "SibSp        -0.2866    0.1061   -2.7002  0.0069  -0.4946  -0.0786\n",
       "Parch        -0.1140    0.1168   -0.9759  0.3291  -0.3429   0.1150\n",
       "Fare          0.2844    0.1359    2.0936  0.0363   0.0182   0.5507\n",
       "Embarked      0.4178    0.1391    3.0034  0.0027   0.1451   0.6904\n",
       "AgeBin        1.4405    0.2150    6.7014  0.0000   1.0192   1.8618\n",
       "CabinLetter   0.2355    0.0529    4.4476  0.0000   0.1317   0.3392\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "X_train = traindf.drop(columns = 'Survived')\n",
    "y_train = traindf[['Survived']].copy()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train,X_train)\n",
    "logit_model.fit().summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df263cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "X_test = testdf\n",
    "#if 'Parch' in X_train.columns:\n",
    "#    X_train = X_train.drop(columns='Parch') # Remove this as it is detrimental to the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f0083c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=10000, multi_class='multinomial', penalty='l1',\n",
      "                   solver='saga', verbose=10)\n",
      "convergence after 65 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marjani\\Anaconda3\\envs\\kaggle_titanic\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver = 'saga', penalty = 'l1', max_iter = 10000, multi_class = 'multinomial', verbose = 10)\n",
    "print(logreg)\n",
    "results = logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2f74105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if 'Parch' in X_test.columns:\n",
    "#    X_test = X_test.drop(columns='Parch') # Remove the Parch column as the P-value is very high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78f9fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "011cc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testLogReg = X_test.copy()\n",
    "X_testLogReg['Survived'] = y_test\n",
    "subLogReg = X_testLogReg\n",
    "subLogReg = subLogReg[[ 'Survived']].copy() #Exract only the survived column as per the instructions\n",
    "subLogReg.to_csv('submissionLogReg.csv') # create a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eeec54",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4587370d",
   "metadata": {},
   "source": [
    "We will now try a different algorithm, random forest, to see if we can improve the results as well as to check which features have insignificant impact on the predictive power and whether they are the same to the ones we found previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7132539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marjani\\AppData\\Local\\Temp/ipykernel_13640/3431117916.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_testRandFor=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d6e4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testRandFor = X_test.copy()\n",
    "X_testRandFor['Survived'] = y_testRandFor\n",
    "subRandFor = X_testRandFor\n",
    "subRandFor = subRandFor[[ 'Survived']].copy() #Exract only the survived column as per the instructions\n",
    "subRandFor.to_csv('submissionRandFor.csv') # create a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5e7ab",
   "metadata": {},
   "source": [
    "# GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "237b8d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegtuned hyperparameters :(best parameters)  {'C': 10.0, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogRegaccuracy : 0.8058313979034587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#grid={\"C\":np.logspace(-5,5,11), \"penalty\":[\"l2\"], \"n_jobs\": [-1]}\n",
    "grid = [\n",
    "  {'C': np.logspace(-5,5,11), \"penalty\":[\"l1\"],\"max_iter\": [2000], \"solver\": [\"liblinear\", \"saga\"]}, #, \"max_iter\": range(100,200)\n",
    "  {'C': np.logspace(-2,2,5),\"max_iter\": [2000], \"penalty\":[\"l2\"], \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\"]},\n",
    "  {'C': np.logspace(-5,5,11), \"max_iter\": [2000], \"penalty\":[\"elasticnet\"], \"n_jobs\": [-1], \"solver\": [\"saga\"], \"l1_ratio\": range(0,1,30), \"n_jobs\": [-1]},\n",
    " ]\n",
    "logreg1=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg1,grid,cv=5)\n",
    "logreg_cv.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "print(\"LogRegtuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"LogRegaccuracy :\",logreg_cv.best_score_)\n",
    "\n",
    "y_testGridSearchCV=logreg_cv.predict(X_test)\n",
    "X_testGridSearchCV = X_test.copy()\n",
    "X_testGridSearchCV['Survived'] = y_testGridSearchCV\n",
    "subGridSearchCV = X_testGridSearchCV\n",
    "subGridSearchCV = subGridSearchCV[[ 'Survived']].copy() #Exract only the survived column as per the instructions\n",
    "subGridSearchCV.to_csv('submissionGridSearchCVLogReg.csv') # create a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c742b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF tuned hyperparameters :(best parameters)  {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 85, 'n_jobs': -1}\n",
      "RF accuracy : 0.827185989580064\n"
     ]
    }
   ],
   "source": [
    "grid = [\n",
    "    {'n_estimators': range(1, 100,2), \"n_jobs\": [-1], \"criterion\": [\"gini\", \"entropy\"], \"max_features\":[\"auto\", \"sqrt\", \"log2\"]},\n",
    "         ]\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "RFclf=RandomForestClassifier()\n",
    "\n",
    "RFclf_cv=GridSearchCV(RFclf,grid,cv=5)\n",
    "RFclf_cv.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "print(\"RF tuned hyperparameters :(best parameters) \",RFclf_cv.best_params_)\n",
    "print(\"RF accuracy :\",RFclf_cv.best_score_)\n",
    "\n",
    "#RF tuned hyperparameters :(best parameters)  {'n_estimators': 20, 'n_jobs': -1}\n",
    "#RF accuracy : 0.8305504990270542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b50cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testGridSearchCVRF=RFclf_cv.predict(X_test)\n",
    "X_testGridSearchCVRF = X_test.copy()\n",
    "X_testGridSearchCVRF['Survived'] = y_testGridSearchCVRF\n",
    "subGridSearchCVRF = X_testGridSearchCVRF\n",
    "subGridSearchCVRF = subGridSearchCVRF[[ 'Survived']].copy() #Exract only the survived column as per the instructions\n",
    "subGridSearchCVRF.to_csv('submissionGridSearchCVRF.csv') # create a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99283aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
