{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c51fe6",
   "metadata": {},
   "source": [
    "# Libraries and data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2dee7",
   "metadata": {},
   "source": [
    "We will first load all the necessary libraries and the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77bb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84bf071",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We now load the data\n",
    "traindf = pd.read_csv('train.csv')  # load the training data\n",
    "testdf = pd.read_csv('test.csv')  # load the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4778ec",
   "metadata": {},
   "source": [
    "# Imputation of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de885720",
   "metadata": {},
   "source": [
    "Let's check what is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2de071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f94a1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c32439",
   "metadata": {},
   "source": [
    "First we will impute the Age column with mean values. If we don't round the numbers to one decimal point there are too many decimal points which add no new knowledge to the age yet if we are working with very large data frames might pose an problem for speed. Ask Danny if this is true.\n",
    "\n",
    "Next, let's explore the Cabin column. This is not a numeric value so using mean or median as an imputation value is meaningless. We can try a random sample from the existing cabin value or something else. \n",
    "One option is to use the most common cabin designation. Considering there are many types it might be appropriate to use Unknown. This way we are not forcing anything on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04960f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeNumerical(dfName, colName):\n",
    "    missing_col = [colName]\n",
    "    # Using mean to impute the missing values\n",
    "    for i in missing_col:\n",
    "        dfName.loc[dfName.loc[:,i].isnull(),i]=round(dfName.loc[:,i].mean(), 2)\n",
    "\n",
    "def imputeCategorical(dfName, colName):\n",
    "    missing_col = [colName]\n",
    "    # Using unknown to impute the missing values\n",
    "    for i in missing_col:\n",
    "        dfName.loc[dfName.loc[:,i].isnull(),i]='Unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160736f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputeNumerical(traindf, 'Age')\n",
    "imputeCategorical(traindf, 'Cabin')\n",
    "imputeCategorical(traindf, 'Embarked')\n",
    "imputeNumerical(testdf, 'Age')\n",
    "imputeNumerical(testdf, 'Fare')\n",
    "imputeCategorical(testdf, 'Cabin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57348e31",
   "metadata": {},
   "source": [
    "# Data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7ff36",
   "metadata": {},
   "source": [
    "We will now bunch the age variable into children, age 0-10, young adults (11-30), adults(31-50) and seniors 50+.\n",
    "We will also bunch the cabin numbers into just the letter in front (ex cabin C85 becomes C, cabin B42 becomes B, etc).\n",
    "Sex will be transformed to male=0, female=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e95e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataEngineering(dfName):\n",
    "    bins = pd.IntervalIndex.from_breaks([0, 10, 31, 51, np.inf], closed='left')\n",
    "    dfName[\"AgeBin\"] = pd.cut(dfName.Age.values, bins).codes\n",
    "\n",
    "    # Transforming the cabin code to only show the letter of it (the first character in the string)\n",
    "    dfName['CabinLetter'] = dfName['Cabin'].astype(str).str[0]\n",
    "\n",
    "    # Sex, Cabin, Embarked to integer\n",
    "    dfName.replace({'Sex': {'female': 0, 'male': 1}}, inplace=True)\n",
    "    dfName.replace({'Embarked': {'S': 0, 'C': 1, 'Q' : 2, 'Unknown':3}}, inplace=True)\n",
    "    dfName.replace({'CabinLetter': {'U':0, 'C':1, 'B':2, 'D':3, 'G':4, 'F':5, 'E':6, 'T':7, 'A':8}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e9a2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataEngineering(traindf)\n",
    "dataEngineering(testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9871706",
   "metadata": {},
   "source": [
    "These two functions below didn't work when implemented in the dataEngineering function so that is why they are out. Ask Danny how to put them back in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f18945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove all the variables that cannot have any effect like Name and Ticket \n",
    "traindf = traindf.drop(columns = ['Name', 'Ticket','Cabin'])\n",
    "testdf = testdf.drop(columns = ['Name', 'Ticket','Cabin'])\n",
    "\n",
    "# We change PassengerID to be the index of the dataframe\n",
    "traindf = traindf.set_index(\"PassengerId\") \n",
    "testdf = testdf.set_index(\"PassengerId\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fac54",
   "metadata": {},
   "source": [
    "# Data normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fa208",
   "metadata": {},
   "source": [
    "Let's look at the unique values in each column to see which can be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653cb75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass [3 2 1]\n",
      "Sex [1 0]\n",
      "Age [34.5  47.   62.   27.   22.   14.   30.   26.   18.   21.   30.27 46.\n",
      " 23.   63.   24.   35.   45.   55.    9.   48.   50.   22.5  41.   33.\n",
      " 18.5  25.   39.   60.   36.   20.   28.   10.   17.   32.   13.   31.\n",
      " 29.   28.5  32.5   6.   67.   49.    2.   76.   43.   16.    1.   12.\n",
      " 42.   53.   26.5  40.   61.   60.5   7.   15.   54.   64.   37.   34.\n",
      " 11.5   8.    0.33 38.   57.   40.5   0.92 19.   36.5   0.75  0.83 58.\n",
      "  0.17 59.   14.5  44.    5.   51.    3.   38.5 ]\n",
      "SibSp [0 1 2 3 4 5 8]\n",
      "Parch [0 1 3 2 4 6 5 9]\n",
      "Fare [  7.8292   7.       9.6875   8.6625  12.2875   9.225    7.6292  29.\n",
      "   7.2292  24.15     7.8958  26.      82.2667  61.175   27.7208  12.35\n",
      "   7.225    7.925   59.4      3.1708  31.6833  61.3792 262.375   14.5\n",
      "  61.9792  30.5     21.6792  31.5     20.575   23.45    57.75     8.05\n",
      "   9.5     56.4958  13.4167  26.55     7.85    13.      52.5542  29.7\n",
      "   7.75    76.2917  15.9     60.      15.0333  23.     263.      15.5792\n",
      "  29.125    7.65    16.1     13.5      7.725   21.       7.8792  42.4\n",
      "  28.5375 211.5     25.7     15.2458 221.7792  10.7083  14.4542  13.9\n",
      "   7.775   52.       7.7958  78.85     7.8542  55.4417   8.5167  22.525\n",
      "   7.8208   8.7125  15.0458   7.7792  31.6792   7.2833   6.4375  16.7\n",
      "  75.2417  15.75     7.25    23.25    28.5     25.4667  46.9    151.55\n",
      "  18.      51.8625  83.1583  35.63    12.1833  31.3875   7.55    13.775\n",
      "   7.7333  22.025   50.4958  34.375    8.9625  39.      36.75    53.1\n",
      " 247.5208  16.      69.55    32.5    134.5     10.5      8.1125  15.5\n",
      "  14.4    227.525   25.7417   7.05    73.5     42.5    164.8667  13.8583\n",
      "  27.4458  15.1     65.       6.4958  71.2833  75.25   106.425   30.\n",
      "   7.8875  27.75   136.7792   9.325   17.4     12.7375   0.      20.2125\n",
      "  39.6      6.95    81.8583  41.5792  45.5      9.35    93.5     14.1083\n",
      "   7.575  135.6333 146.5208 211.3375  79.2     15.7417   7.5792 512.3292\n",
      "  63.3583  51.4792  15.55    37.0042  14.4583  39.6875  11.5     50.\n",
      "  12.875   21.075   39.4     20.25    47.1     13.8625   7.7208  90.\n",
      " 108.9     22.3583]\n",
      "Embarked [2 0 1]\n",
      "AgeBin [2 3 1 0]\n",
      "CabinLetter [0 2 6 8 1 3 5 4]\n"
     ]
    }
   ],
   "source": [
    "for col in testdf:\n",
    "    print(col, testdf[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56e774",
   "metadata": {},
   "source": [
    "We see that Fare and Age are the only ones that should be normalized. The rest have only few unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b977ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(df): # A function to normalize only select columns ina  dataframe\n",
    "    col_names = ['Age', 'Fare']\n",
    "    features = df[col_names]\n",
    "    scaler = preprocessing.StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    "    df[col_names] = features\n",
    "# Ask Danny how to manke a function that has variable input. \n",
    "# Now are age and fare to be scaled but what if we need to omit fare or maybe add two more columns to be scaled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901909ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleData(traindf)\n",
    "scaleData(testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c31afe",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81295ea",
   "metadata": {},
   "source": [
    "We will split the data in X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d975033",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.447156\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.329</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>Survived</td>           <td>AIC:</td>         <td>814.8312</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-10-14 10:27</td>       <td>BIC:</td>         <td>857.9623</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>891</td>        <td>Log-Likelihood:</td>    <td>-398.42</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>8</td>            <td>LL-Null:</td>        <td>-593.33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>882</td>         <td>LLR p-value:</td>    <td>2.8111e-79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>        <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass</th>      <td>-0.4820</td>  <td>0.1235</td>   <td>-3.9020</td> <td>0.0001</td> <td>-0.7242</td> <td>-0.2399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex</th>         <td>-2.5310</td>  <td>0.1925</td>  <td>-13.1473</td> <td>0.0000</td> <td>-2.9084</td> <td>-2.1537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>         <td>-1.3767</td>  <td>0.1883</td>   <td>-7.3110</td> <td>0.0000</td> <td>-1.7458</td> <td>-1.0076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SibSp</th>       <td>-0.2866</td>  <td>0.1061</td>   <td>-2.7001</td> <td>0.0069</td> <td>-0.4946</td> <td>-0.0786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Parch</th>       <td>-0.1140</td>  <td>0.1168</td>   <td>-0.9759</td> <td>0.3291</td> <td>-0.3430</td> <td>0.1150</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fare</th>        <td>0.2844</td>   <td>0.1359</td>   <td>2.0937</td>  <td>0.0363</td> <td>0.0182</td>  <td>0.5507</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked</th>    <td>0.4178</td>   <td>0.1391</td>   <td>3.0035</td>  <td>0.0027</td> <td>0.1451</td>  <td>0.6904</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AgeBin</th>      <td>1.4405</td>   <td>0.2150</td>   <td>6.7013</td>  <td>0.0000</td> <td>1.0192</td>  <td>1.8618</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CabinLetter</th> <td>0.2355</td>   <td>0.0529</td>   <td>4.4476</td>  <td>0.0000</td> <td>0.1317</td>  <td>0.3392</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.329     \n",
       "Dependent Variable: Survived         AIC:              814.8312  \n",
       "Date:               2021-10-14 10:27 BIC:              857.9623  \n",
       "No. Observations:   891              Log-Likelihood:   -398.42   \n",
       "Df Model:           8                LL-Null:          -593.33   \n",
       "Df Residuals:       882              LLR p-value:      2.8111e-79\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     6.0000                                       \n",
       "------------------------------------------------------------------\n",
       "              Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "------------------------------------------------------------------\n",
       "Pclass       -0.4820    0.1235   -3.9020  0.0001  -0.7242  -0.2399\n",
       "Sex          -2.5310    0.1925  -13.1473  0.0000  -2.9084  -2.1537\n",
       "Age          -1.3767    0.1883   -7.3110  0.0000  -1.7458  -1.0076\n",
       "SibSp        -0.2866    0.1061   -2.7001  0.0069  -0.4946  -0.0786\n",
       "Parch        -0.1140    0.1168   -0.9759  0.3291  -0.3430   0.1150\n",
       "Fare          0.2844    0.1359    2.0937  0.0363   0.0182   0.5507\n",
       "Embarked      0.4178    0.1391    3.0035  0.0027   0.1451   0.6904\n",
       "AgeBin        1.4405    0.2150    6.7013  0.0000   1.0192   1.8618\n",
       "CabinLetter   0.2355    0.0529    4.4476  0.0000   0.1317   0.3392\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "X_train = traindf.drop(columns = 'Survived')\n",
    "y_train = traindf[['Survived']].copy()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train,X_train)\n",
    "logit_model.fit().summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df263cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "X_test = testdf\n",
    "if 'Parch' in X_train.columns:\n",
    "    X_train = X_train.drop(columns='Parch') # Remove this as it is detrimental to the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f0083c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=10000, multi_class='multinomial', penalty='l1',\n",
      "                   solver='saga', verbose=10)\n",
      "convergence after 65 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marjani\\Anaconda3\\envs\\kaggle_titanic\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver = 'saga', penalty = 'l1', max_iter = 10000, multi_class = 'multinomial', verbose = 10)\n",
    "print(logreg)\n",
    "results = logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f74105",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Parch' in X_test.columns:\n",
    "    X_test = X_test.drop(columns='Parch') # Remove the Parch column as the P-value is very high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78f9fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "011cc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testLogReg = X_test.copy()\n",
    "X_testLogReg['Survived'] = y_test\n",
    "subLogReg = X_testLogReg\n",
    "subLogReg = subLogReg[[ 'Survived']].copy() #Exract only the survived column as per the instructions\n",
    "subLogReg.to_csv('submissionLogReg.csv') # create a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eeec54",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4587370d",
   "metadata": {},
   "source": [
    "We will now try a different algorith, random forest, to see if we can improve the results as well as to check which features have insignificant impact on the predictive power and whether they are the same to the ones we found previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7132539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marjani\\AppData\\Local\\Temp/ipykernel_11140/3431117916.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_testRandFor=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d6e4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testRandFor = X_test.copy()\n",
    "X_testRandFor['Survived'] = y_testRandFor\n",
    "subRandFor = X_testRandFor\n",
    "subRandFor = subRandFor[[ 'Survived']].copy() #Exract only the survived column as per the instructions\n",
    "subRandFor.to_csv('submissionRandFor.csv') # create a csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
