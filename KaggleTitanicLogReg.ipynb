{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c51fe6",
   "metadata": {},
   "source": [
    "# Libraries and data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2dee7",
   "metadata": {},
   "source": [
    "We will first load all the necessary libraries and the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77bb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84bf071",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We now load the data\n",
    "traindf = pd.read_csv('train.csv')  # load the training data\n",
    "testdf = pd.read_csv('test.csv')  # load the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4778ec",
   "metadata": {},
   "source": [
    "# Imputation of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de885720",
   "metadata": {},
   "source": [
    "Let's check what is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2de071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f94a1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c32439",
   "metadata": {},
   "source": [
    "First we will impute the Age column with mean values. If we don't round the numbers to one decimal point there are too many decimal points which add no new knowledge to the age yet if we are working with very large data frames might pose an problem for speed. Ask Danny if this is true.\n",
    "\n",
    "Next, let's explore the Cabin column. This is not a numeric value so using mean or median as an imutation value is meaningless. We can try a random sample from the existing cabin value or something else. \n",
    "One option is to use the most common cabin designation. Considering there are many types it might be appropriate to use Unknown. This way we are not forcing anything on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04960f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeNumerical(dfName, colName):\n",
    "    missing_col = [colName]\n",
    "    #Technique 1: Using mean to impute the missing values\n",
    "    for i in missing_col:\n",
    "        dfName.loc[dfName.loc[:,i].isnull(),i]=round(dfName.loc[:,i].mean(), 2)\n",
    "\n",
    "def imputeCategorical(dfName, colName):\n",
    "    missing_col = [colName]\n",
    "    #Technique 1: Using mean to impute the missing values\n",
    "    for i in missing_col:\n",
    "        dfName.loc[dfName.loc[:,i].isnull(),i]='Unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160736f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputeNumerical(traindf, 'Age')\n",
    "imputeCategorical(traindf, 'Cabin')\n",
    "imputeCategorical(traindf, 'Embarked')\n",
    "imputeNumerical(testdf, 'Age')\n",
    "imputeNumerical(testdf, 'Fare')\n",
    "imputeCategorical(testdf, 'Cabin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57348e31",
   "metadata": {},
   "source": [
    "# Data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7ff36",
   "metadata": {},
   "source": [
    "We will now bunch the age variable into children, age 0-10, young adults (11-30), adults(31-50) and seniors 50+.\n",
    "We will also bunch the cabin numbers into just the letter in front (ex cabin C85 becomes C, cabin B42 becomes B, etc).\n",
    "Sex will be transformed to male=0, female=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e95e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataEngineering(dfName):\n",
    "    bins = pd.IntervalIndex.from_breaks([0, 10, 31, 51, np.inf], closed='left')\n",
    "    dfName[\"AgeBin\"] = pd.cut(dfName.Age.values, bins).codes\n",
    "\n",
    "    # Transforming the cabin code to only show the letter of it (the first character in the string)\n",
    "    dfName['CabinLetter'] = dfName['Cabin'].astype(str).str[0]\n",
    "\n",
    "    # Sex, Cabin, Embarked to integer\n",
    "    dfName.replace({'Sex': {'female': 0, 'male': 1}}, inplace=True)\n",
    "    dfName.replace({'Embarked': {'S': 0, 'C': 1, 'Q' : 2, 'Unknown':3}}, inplace=True)\n",
    "    dfName.replace({'CabinLetter': {'U':0, 'C':1, 'B':2, 'D':3, 'G':4, 'F':5, 'E':6, 'T':7, 'A':8}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e9a2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataEngineering(traindf)\n",
    "dataEngineering(testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9871706",
   "metadata": {},
   "source": [
    "These two functions below didn't work when implemented in dataEngineering so that is why they are out. Ask Danny how to put them back in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f18945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove all the variables that cannot have any effect like Name and Ticket \n",
    "traindf = traindf.drop(columns = ['Name', 'Ticket','Cabin'])\n",
    "testdf = testdf.drop(columns = ['Name', 'Ticket','Cabin'])\n",
    "\n",
    "# We change PassengerID to be the index of the dataframe\n",
    "traindf = traindf.set_index(\"PassengerId\") \n",
    "testdf = testdf.set_index(\"PassengerId\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fac54",
   "metadata": {},
   "source": [
    "# Data normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fa208",
   "metadata": {},
   "source": [
    "Let's look at the unique values in each column to see which can be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653cb75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass [3 1 2]\n",
      "Sex [1 0]\n",
      "Age [22.   38.   26.   35.   29.7  54.    2.   27.   14.    4.   58.   20.\n",
      " 39.   55.   31.   34.   15.   28.    8.   19.   40.   66.   42.   21.\n",
      " 18.    3.    7.   49.   29.   65.   28.5   5.   11.   45.   17.   32.\n",
      " 16.   25.    0.83 30.   33.   23.   24.   46.   59.   71.   37.   47.\n",
      " 14.5  70.5  32.5  12.    9.   36.5  51.   55.5  40.5  44.    1.   61.\n",
      " 56.   50.   36.   45.5  20.5  62.   41.   52.   63.   23.5   0.92 43.\n",
      " 60.   10.   64.   13.   48.    0.75 53.   57.   80.   70.   24.5   6.\n",
      "  0.67 30.5   0.42 34.5  74.  ]\n",
      "SibSp [1 0 3 4 2 5 8]\n",
      "Parch [0 1 2 5 3 4 6]\n",
      "Fare [  7.25    71.2833   7.925   53.1      8.05     8.4583  51.8625  21.075\n",
      "  11.1333  30.0708  16.7     26.55    31.275    7.8542  16.      29.125\n",
      "  13.      18.       7.225   26.       8.0292  35.5     31.3875 263.\n",
      "   7.8792   7.8958  27.7208 146.5208   7.75    10.5     82.1708  52.\n",
      "   7.2292  11.2417   9.475   21.      41.5792  15.5     21.6792  17.8\n",
      "  39.6875   7.8     76.7292  61.9792  27.75    46.9     80.      83.475\n",
      "  27.9     15.2458   8.1583   8.6625  73.5     14.4542  56.4958   7.65\n",
      "  29.      12.475    9.       9.5      7.7875  47.1     15.85    34.375\n",
      "  61.175   20.575   34.6542  63.3583  23.      77.2875   8.6542   7.775\n",
      "  24.15     9.825   14.4583 247.5208   7.1417  22.3583   6.975    7.05\n",
      "  14.5     15.0458  26.2833   9.2167  79.2      6.75    11.5     36.75\n",
      "   7.7958  12.525   66.6      7.3125  61.3792   7.7333  69.55    16.1\n",
      "  15.75    20.525   55.      25.925   33.5     30.6958  25.4667  28.7125\n",
      "   0.      15.05    39.      22.025   50.       8.4042   6.4958  10.4625\n",
      "  18.7875  31.     113.275   27.      76.2917  90.       9.35    13.5\n",
      "   7.55    26.25    12.275    7.125   52.5542  20.2125  86.5    512.3292\n",
      "  79.65   153.4625 135.6333  19.5     29.7     77.9583  20.25    78.85\n",
      "  91.0792  12.875    8.85   151.55    30.5     23.25    12.35   110.8833\n",
      " 108.9     24.      56.9292  83.1583 262.375   14.     164.8667 134.5\n",
      "   6.2375  57.9792  28.5    133.65    15.9      9.225   35.      75.25\n",
      "  69.3     55.4417 211.5      4.0125 227.525   15.7417   7.7292  12.\n",
      " 120.      12.65    18.75     6.8583  32.5      7.875   14.4     55.9\n",
      "   8.1125  81.8583  19.2583  19.9667  89.1042  38.5      7.725   13.7917\n",
      "   9.8375   7.0458   7.5208  12.2875   9.5875  49.5042  78.2667  15.1\n",
      "   7.6292  22.525   26.2875  59.4      7.4958  34.0208  93.5    221.7792\n",
      " 106.425   49.5     71.      13.8625   7.8292  39.6     17.4     51.4792\n",
      "  26.3875  30.      40.125    8.7125  15.      33.      42.4     15.55\n",
      "  65.      32.3208   7.0542   8.4333  25.5875   9.8417   8.1375  10.1708\n",
      " 211.3375  57.      13.4167   7.7417   9.4833   7.7375   8.3625  23.45\n",
      "  25.9292   8.6833   8.5167   7.8875  37.0042   6.45     6.95     8.3\n",
      "   6.4375  39.4     14.1083  13.8583  50.4958   5.       9.8458  10.5167]\n",
      "Embarked [0 1 2 3]\n",
      "AgeBin [1 2 3 0]\n",
      "CabinLetter [0 1 6 4 3 8 2 5 7]\n"
     ]
    }
   ],
   "source": [
    "for col in testdf:\n",
    "    print(col, traindf[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56e774",
   "metadata": {},
   "source": [
    "We see that Fare and Age are the only ones that should be normalized. The rest have only few unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b977ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(df): # A function to normalize only select columns ina  dataframe\n",
    "    col_names = ['Age', 'Fare']\n",
    "    features = df[col_names]\n",
    "    scaler = preprocessing.StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    "    df[col_names] = features\n",
    "# Ask Danny how to manke a function that has variable input. \n",
    "# Now are age and fare to be scaled but what if we need to omit fare or maybe add two more columns to be scaled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901909ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleData(traindf)\n",
    "scaleData(testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c31afe",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81295ea",
   "metadata": {},
   "source": [
    "For simplicity we will split the data in X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d975033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.447156\n",
      "         Iterations 6\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.329     \n",
      "Dependent Variable: Survived         AIC:              814.8312  \n",
      "Date:               2021-10-07 14:30 BIC:              857.9623  \n",
      "No. Observations:   891              Log-Likelihood:   -398.42   \n",
      "Df Model:           8                LL-Null:          -593.33   \n",
      "Df Residuals:       882              LLR p-value:      2.8111e-79\n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     6.0000                                       \n",
      "------------------------------------------------------------------\n",
      "              Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
      "------------------------------------------------------------------\n",
      "Pclass       -0.4820    0.1235   -3.9020  0.0001  -0.7242  -0.2399\n",
      "Sex          -2.5310    0.1925  -13.1473  0.0000  -2.9084  -2.1537\n",
      "Age          -1.3767    0.1883   -7.3110  0.0000  -1.7458  -1.0076\n",
      "SibSp        -0.2866    0.1061   -2.7001  0.0069  -0.4946  -0.0786\n",
      "Parch        -0.1140    0.1168   -0.9759  0.3291  -0.3430   0.1150\n",
      "Fare          0.2844    0.1359    2.0937  0.0363   0.0182   0.5507\n",
      "Embarked      0.4178    0.1391    3.0035  0.0027   0.1451   0.6904\n",
      "AgeBin        1.4405    0.2150    6.7013  0.0000   1.0192   1.8618\n",
      "CabinLetter   0.2355    0.0529    4.4476  0.0000   0.1317   0.3392\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "X_train = traindf.drop(columns = 'Survived')\n",
    "y_train = traindf[['Survived']].copy()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train,X_train)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df263cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "X_test = testdf\n",
    "X_train = X_train.drop(columns='Parch') # Remove this as it is detrimental to the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f0083c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marjani\\Anaconda3\\envs\\kaggle_titanic\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f74105",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(columns='Parch') # Remove the Parch column as the P-value is very high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78f9fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "011cc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Survived'] = y_test\n",
    "sub = X_test\n",
    "sub = sub[[ 'Survived']].copy() #Exract only the survived column as per the instructions\n",
    "sub.to_csv('submission.csv') # create a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805eeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
